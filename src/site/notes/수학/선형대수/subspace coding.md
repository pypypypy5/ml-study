---
{"dg-publish":true,"permalink":"///subspace-coding/"}
---

1. 두 벡터가 직교한다면 더해도 정보가 유지된다.

동쪽 벡터+북쪽 벡터=동북쪽인데, 각 벡터가 직교, 그리고 원래 어느 방향인지를 안다면 분리가 가능한 것.

1. [[수학/선형대수/orthogonal matrix\|orthogonal matrix]]을 통한 변환은 정보 손실이 없다

방향만 바꾸기 때문. 압축이 존재하지 않아서 원본 변환의 역행렬 곱하면 완벽 복원된다.

1. 고차원 공간에서는 서로 직교하는 서로 다른 벡터가 엄청나게 많다.

→ 고차원 벡터들을 서로 직교하게 만들고, 더하면 덧셈임에도 정보를 보존할 수 있다.

+[[수학/선형대수/SVD\|SVD]]를 떠올리자. 선형 변환은 축 변환 + 축 따라 늘이기 + 차원 축소/확대 인데, 직교 행렬은 축 변환만 수행

→ 직교 행렬 결과 어느 축으로 이동하는지를 정할 수 있다 → 1번 w가 1~10번 차원, 2번 w가 11~20번 차원을 점유하도록 하면 w1h1은 w2h2와 직교한다는게 보장된다.

→ 직교 행렬들로 각 벡터 변환하고, 벡터들 전부 더하면 나중에 완벽히 분리, 복원 가능!