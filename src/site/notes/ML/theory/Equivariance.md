---
{"dg-publish":true,"permalink":"/ml/theory/equivariance/"}
---

F(Tx)=T(Fx)

두 변환을 어느것을 먼저 하건 결과가 같게 나온다는 것.

일반 attention은 토큰 순서 뒤섞어도 결과가 똑같이 나온다. 순서 관계없이 토큰들 사이의 관계만을 생각하기 때문에 그런 것이며, 때문에 positional encoding이 필요한 것이다.